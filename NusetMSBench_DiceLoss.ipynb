{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a78b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli temel kütüphaneler\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch ve torchvision modülleri\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# PyTorch ile TensorBoard için gerekli\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# MedSegBench veri kümesi\n",
    "from medsegbench import NusetMSBench\n",
    "\n",
    "# Sklearn metrikleri\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, jaccard_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671e7708",
   "metadata": {},
   "source": [
    "# Dataset için gerekli dönüşümler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f570a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = NusetMSBench(split='train', size=256, transform=transform, target_transform = transform, download=True)\n",
    "val_dataset = NusetMSBench(split='val', size=256, transform=transform, target_transform = transform, download=True)\n",
    "test_dataset = NusetMSBench(split='test', size=256,  transform=transform, target_transform = transform, download=True)\n",
    "\n",
    "# Print the number of samples in each dataset\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "bs = 8\n",
    "\n",
    "# DataLoader for training, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "#Print the number of batches in each DataLoader\n",
    "print(f\"Number of batches in training set: {len(train_loader)}\")\n",
    "print(f\"Number of batches in validation set: {len(val_loader)}\")\n",
    "print(f\"Number of batches in test set: {len(test_loader)}\")\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "print(f\"Image size: {train_dataset[0][0].shape}\")\n",
    "print(f\"Label size: {train_dataset[0][1].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff792f",
   "metadata": {},
   "source": [
    "# Loss fonksiyonunu tanımlıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)  # BCEWithLogitsLoss gibi logits veriyorsun, o yüzden sigmoid uygula\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
    "\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793ea58",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # Skip connection\n",
    "        out = self.relu(self.bn1(self.conv1(x))) # İlk konvolüsyon ve aktivasyon\n",
    "        out = self.bn2(self.conv2(out)) # İkinci konvolüsyon\n",
    "\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x) # Skip connection boyutunu eşleştir\n",
    "        out += identity # Skip connection\n",
    "        return self.relu(out) \n",
    "\n",
    "class ResNet18_UNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        self.encoder1 = self._make_layer(64, 2)\n",
    "        self.encoder2 = self._make_layer(128, 2, stride=2)\n",
    "        self.encoder3 = self._make_layer(256, 2, stride=2)\n",
    "        self.encoder4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder4 = self.upsample_block(512, 256)\n",
    "        self.decoder3 = self.upsample_block(256, 128)\n",
    "        self.decoder2 = self.upsample_block(128, 64)\n",
    "        self.decoder1 = self.upsample_block(64, 64)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride=1):\n",
    "        layers = [BasicBlock(self.in_channels, out_channels, stride)]\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def upsample_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        x2 = self.maxpool(x1)\n",
    "        e1 = self.encoder1(x2)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "\n",
    "        d4 = self.decoder4(e4) + e3\n",
    "        d3 = self.decoder3(d4) + e2\n",
    "        d2 = self.decoder2(d3) + e1\n",
    "        d1 = self.decoder1(d2) + x1\n",
    "\n",
    "        out = self.final_conv(d1)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = ResNet18_UNet(n_classes=1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = DiceLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7e2d2",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard Writer\n",
    "writer = SummaryWriter(log_dir=\"./logs/NusetMSBenchDiceLoss\")\n",
    "\n",
    "num_epochs = 150\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_val_loss = float(\"inf\")  # En düşük doğrulama kaybı için başlangıç değeri\n",
    "\n",
    "save_dir = \"./checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Checkpoint klasörü oluştur\n",
    "log_file_path = os.path.join(save_dir, \"NusetMSBenchDiceLoss.txt\")  # TXT dosyası yolu\n",
    "\n",
    "# Accuracy hesaplamak için yardımcı fonksiyon\n",
    "def compute_accuracy(pred_mask, true_mask):\n",
    "    correct = (pred_mask == true_mask).sum().float()\n",
    "    total = true_mask.numel()\n",
    "    accuracy = correct / total\n",
    "    return accuracy.item()\n",
    "\n",
    "# Eğitim\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Etiketleri boyutlandır\n",
    "        labels = F.interpolate(labels, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Modeli çalıştır ve çıktı al\n",
    "        logits_mask = model(inputs)\n",
    "\n",
    "        # Kayıp hesaplama\n",
    "        loss = criterion(logits_mask, labels)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        # Accuracy hesaplama\n",
    "        prob_mask = logits_mask.sigmoid()\n",
    "        pred_mask = (prob_mask > 0.5).float()\n",
    "        true_mask = (labels > 0.5).float()  # Etiketleri ikili formata çeviriyoruz\n",
    "        acc = compute_accuracy(pred_mask, true_mask)\n",
    "        train_acc.append(acc)\n",
    "\n",
    "        # Geri yayılım\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Değerleri kaydet\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Etiketleri boyutlandır\n",
    "            labels = F.interpolate(labels, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "\n",
    "            logits_mask = model(inputs)\n",
    "            loss = criterion(logits_mask, labels)\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            prob_mask = logits_mask.sigmoid()\n",
    "            pred_mask = (prob_mask > 0.5).float()\n",
    "            true_mask = (labels > 0.5).float()  # Etiketleri ikili formata çeviriyoruz\n",
    "            acc = compute_accuracy(pred_mask, true_mask)\n",
    "            val_acc.append(acc)\n",
    "\n",
    "            # TensorBoard'a validasyon görsellerini ekle\n",
    "            if epoch % 5 == 0:  # Her 5 epokta bir görsel kaydet\n",
    "                writer.add_images('Validation/Input', inputs, epoch)\n",
    "                writer.add_images('Validation/Predicted', pred_mask, epoch)\n",
    "                writer.add_images('Validation/Target', true_mask, epoch)\n",
    "\n",
    "    # Epoch sonu çıktılar\n",
    "    train_loss_avg = sum(train_loss) / len(train_loss)\n",
    "    train_acc_avg = sum(train_acc) / len(train_acc)\n",
    "    val_loss_avg = sum(val_loss) / len(val_loss)\n",
    "    val_acc_avg = sum(val_acc) / len(val_acc)\n",
    "    \n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {train_loss_avg:.4f} | Accuracy: {train_acc_avg:.4f}\")\n",
    "    print(f\"            Val Loss:   {val_loss_avg:.4f} | Accuracy: {val_acc_avg:.4f}\")\n",
    "\n",
    "\n",
    "    # TensorBoard\n",
    "    writer.add_scalars(\n",
    "        \"Loss\", {\"Train\": train_loss_avg, \"Validation\": val_loss_avg}, epoch\n",
    "    )\n",
    "    writer.add_scalars(\n",
    "        \"Accuracy\", {\"Train\": train_acc_avg, \"Validation\": val_acc_avg}, epoch\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Sonuçları txt dosyasına kaydet\n",
    "    with open(log_file_path, \"a\") as f:\n",
    "        f.write(f\"Epoch {epoch+1}/{num_epochs}\\n\")\n",
    "        f.write(f\"Train Loss: {train_loss_avg:.4f} | Train Accuracy: {train_acc_avg:.4f}\\n\")\n",
    "        f.write(f\"Val Loss:   {val_loss_avg:.4f} | Val Accuracy:   {val_acc_avg:.4f}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "    # En düşük validasyon kaybını bul ve en iyi modeli kaydet\n",
    "    current_val_loss = val_loss_avg\n",
    "    if current_val_loss < best_val_loss:\n",
    "        best_val_loss = current_val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"NusetMSBenchDiceLoss.pt\"))\n",
    "        print(f\"En iyi model kaydedildi. Kayıp: {best_val_loss:.4f}\")\n",
    "\n",
    "        # En iyi modeli txt'ye de kaydet\n",
    "        with open(log_file_path, \"a\") as f:\n",
    "            f.write(f\"--> En iyi model kaydedildi. Validation Loss: {best_val_loss:.4f}\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\")\n",
    "     \n",
    "    print(\"\")       \n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e4e4ce",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_evaluate(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "\n",
    "    # Değerlendirme metriklerinin saklanması\n",
    "    all_true_masks = []\n",
    "    all_pred_masks = []\n",
    "    input_images = []   # Görselleri saklamak için\n",
    "    true_masks = []\n",
    "    pred_masks = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            prob_mask = torch.sigmoid(outputs)\n",
    "            pred_mask = (prob_mask > 0.5).float()\n",
    "\n",
    "            # 256x256 boyuta getir\n",
    "            pred_mask_resized = F.interpolate(pred_mask, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "\n",
    "            all_true_masks.append(labels.cpu().numpy())\n",
    "            all_pred_masks.append(pred_mask_resized.cpu().numpy())\n",
    "\n",
    "            # İlk birkaç örneği kaydet (görselleştirme için)\n",
    "            for i in range(inputs.size(0)):\n",
    "                if len(input_images) >= num_samples:\n",
    "                    break\n",
    "                input_images.append(inputs[i].cpu().squeeze().numpy())\n",
    "                true_masks.append(labels[i].cpu().squeeze().numpy())\n",
    "                pred_masks.append(pred_mask_resized[i].cpu().squeeze().numpy())\n",
    "\n",
    "            if len(input_images) >= num_samples:\n",
    "                break\n",
    "\n",
    "    # --- METRİKLERİ HESAPLA VE YAZDIR ---\n",
    "    all_true_masks = np.concatenate(all_true_masks, axis=0).flatten()\n",
    "    all_pred_masks = np.concatenate(all_pred_masks, axis=0).flatten()\n",
    "    all_pred_masks = (all_pred_masks > 0.5).astype(np.float32)\n",
    "\n",
    "    accuracy = accuracy_score(all_true_masks, all_pred_masks)\n",
    "    precision = precision_score(all_true_masks, all_pred_masks)\n",
    "    recall = recall_score(all_true_masks, all_pred_masks)\n",
    "    f1 = f1_score(all_true_masks, all_pred_masks)\n",
    "    iou = jaccard_score(all_true_masks, all_pred_masks)\n",
    "\n",
    "    print(\"=== Overall Metrics ===\")\n",
    "    print(f\"Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "    print(f\"F1-Score : {f1:.4f}\")\n",
    "    print(f\"IoU      : {iou:.4f}\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    # --- GÖRSELLERİ GÖSTER ---\n",
    "    for idx in range(len(input_images)):\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axs[0].imshow(input_images[idx], cmap='gray')\n",
    "        axs[0].set_title('Input Image')\n",
    "        axs[1].imshow(true_masks[idx], cmap='gray')\n",
    "        axs[1].set_title('Ground Truth')\n",
    "        axs[2].imshow(pred_masks[idx], cmap='gray')\n",
    "        axs[2].set_title('Predicted Mask')\n",
    "        for ax in axs:\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Modeli yükleyip test et\n",
    "model = ResNet18_UNet(n_classes=1).to(device)\n",
    "model.load_state_dict(torch.load(\"./checkpoints/NusetMSBenchDiceLoss.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "test_and_evaluate(model, test_loader, device, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a573d",
   "metadata": {},
   "source": [
    "# Model Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c495070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ResNet18_UNet(n_classes=1).to(device)\n",
    "model.load_state_dict(torch.load(\"./checkpoints/NusetMSBenchDiceLoss.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# Görselleştirme başlar\n",
    "for inputs, labels in test_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_mask = model(inputs)\n",
    "        prob_mask = logits_mask.sigmoid()\n",
    "        pred_mask = (prob_mask > 0.5).float()\n",
    "\n",
    "        # Boyutları eşitle: Tahmin maskesini, ground truth (labels) ile aynı boyuta getir\n",
    "        pred_mask = F.interpolate(pred_mask, size=labels.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "    batch_size = inputs.shape[0]\n",
    "    plt.figure(figsize=(15, batch_size * 4))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        img = inputs[i, 0].cpu().numpy()\n",
    "        true = labels[i, 0].cpu().numpy()\n",
    "        pred = pred_mask[i, 0].cpu().numpy()\n",
    "\n",
    "        # Doğru - Hatalı maskesi\n",
    "        correct = (true == pred)\n",
    "        error_map = np.zeros((*true.shape, 3))\n",
    "        error_map[correct] = [0, 1, 0]     # Doğru -> Yeşil\n",
    "        error_map[~correct] = [1, 0, 0]    # Hatalı -> Kırmızı\n",
    "\n",
    "        # Giriş görüntüsü\n",
    "        plt.subplot(batch_size, 4, i * 4 + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(\"Girdi Görüntü\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Gerçek maske\n",
    "        plt.subplot(batch_size, 4, i * 4 + 2)\n",
    "        plt.imshow(true, cmap='gray')\n",
    "        plt.title(\"Gerçek Maske\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Tahmin maskesi\n",
    "        plt.subplot(batch_size, 4, i * 4 + 3)\n",
    "        plt.imshow(pred, cmap='viridis')\n",
    "        plt.title(\"Tahmin Maske\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Hata görselleştirme\n",
    "        plt.subplot(batch_size, 4, i * 4 + 4)\n",
    "        plt.imshow(error_map)\n",
    "        plt.title(\"Doğru (Yeşil) / Hatalı (Kırmızı)\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break  # Sadece ilk batch'i göster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
